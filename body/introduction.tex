\chapter{绪论}

    \section{选题背景及研究意义}
    
        \subsection{选题背景}
        一直以来，强化学习和机器人学都是人工智能研究中的热门领域。在2008年，Deepmind团队基于深度强化学习研发的围棋人工智能系统AlphaGo Zero在零知识自我对弈的情况下在几天之内超越了旧的系统AlphaGo，而AlphaGo曾击败了围棋领域中世界公认的专家柯洁等人\cite{silver2018general}。这项研究使越来越多的人们开始关注人工智能领域，并使得强化学习成为研究热点。事实上，强化学习已经成为最热门的研究领域之一，并在自动控制、运筹学、机器人学、游戏智能体和无人驾驶等领域中获得了广泛的应用\cite{dosovitskiy2017carla}。在这些领域中，机器人学是和前沿强化学习算法关系最密切的领域之一。传统的机器人如机械臂、四足机器人等，可以用强化学习训练得到的智能体进行控制，并在与环境交互过程中根据环境反馈使策略得到进一步的优化。

        然而，由于机器人设计和制造的成本较高，通用的多关节机器人通常非常昂贵。而且机器人通常容易在强化学习中的各种随机探索中受到损坏，并导致控制系统和智能体策略在训练过程中出现错误。因此在实际的机器人上进行所有强化学习训练是不现实的\cite{toussaint2018differentiable, todorov2012mujoco}。为了避免这个问题，可以使用物理仿真引擎对机器人和环境进行建模，并在实际测试智能体之前先在仿真环境中对智能体进行训练。幸运的是，随着强化学习仿真需求的增加，越来越多的针对机器人的仿真环境开始出现，在这些仿真环境中，可以像在真实环境中一样控制机器人的关节、调节各种参数，或获得传感器数据等等，并可以做到在真实环境中难以做到的设定复杂的稀疏奖励、获取碰撞次数、和改变环境的物理参数等操作\cite{savva2019habitat}。

        虽然已经有大量的软件系统可以用于在一个环境建模完全精确的情形下解决一个良定义的任务\cite{toussaint2018differentiable}，如何让智能体在面对未知的新环境和未知的新任务后能够有效泛化之前学习到的策略仍然是一个未完全解决的问题。人类可以在陌生的环境中用很少次数的探索自然地掌握大量有效信息，还可以利用已有经验对大量物体进行分类、提高对物理实体运动的预测能力，或创新性地设计工具解决问题。由于人们对大脑的工作原理仍然知之甚少，这个过程通常很难被数值化为一个单一的奖励函数或强化学习算法。

        本课题致力于解决上述问题，即设计算法从而可以训练出能在任务奖励未知的环境中进行探索，获取环境信息，学习基本策略，并在任务确定后快速调节旧策略以适应新任务的智能体。为了实现这个目标，需要利用现有的开源物理仿真引擎、前沿的强化学习算法和具有强大函数拟合能力的深度神经网络来设计新算法。
        
        \subsection{研究意义}
    
    \section{国内外研究进展}

        \subsection{逻辑编程}

        \subsection{模型预测控制}

    \section{研究内容和方法}

        \subsection{研究内容}

        \subsection{研究方法}

